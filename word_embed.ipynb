{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings:\n",
    "> Word embeddings are essential in various natural language processing tasks, including speech translation, voice cloning, and emotion transfer. They help represent words in a continuous vector space, capturing semantic relationships between words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample sentences (replace with your dataset)\n",
    "sentences = [\n",
    "    [\"I\", \"love\", \"programming\"],\n",
    "    [\"Machine\", \"learning\", \"is\", \"interesting\"],\n",
    "    [\"Python\", \"is\", \"a\", \"popular\", \"language\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Word2Vec model\n",
    "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, sg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "model.save(\"word2vec_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for 'programming': [-9.5785465e-03  8.9431154e-03  4.1650687e-03  9.2347348e-03\n",
      "  6.6435025e-03  2.9247368e-03  9.8040197e-03 -4.4246409e-03\n",
      " -6.8033109e-03  4.2273807e-03  3.7290000e-03 -5.6646108e-03\n",
      "  9.7047603e-03 -3.5583067e-03  9.5494064e-03  8.3472609e-04\n",
      " -6.3384566e-03 -1.9771170e-03 -7.3770545e-03 -2.9795230e-03\n",
      "  1.0416972e-03  9.4826873e-03  9.3558477e-03 -6.5958775e-03\n",
      "  3.4751510e-03  2.2755705e-03 -2.4893521e-03 -9.2291720e-03\n",
      "  1.0271263e-03 -8.1657059e-03  6.3201892e-03 -5.8000805e-03\n",
      "  5.5354391e-03  9.8337233e-03 -1.6000033e-04  4.5284927e-03\n",
      " -1.8094003e-03  7.3607611e-03  3.9400971e-03 -9.0103243e-03\n",
      " -2.3985039e-03  3.6287690e-03 -9.9568366e-05 -1.2012708e-03\n",
      " -1.0554385e-03 -1.6716016e-03  6.0495257e-04  4.1650953e-03\n",
      " -4.2527914e-03 -3.8336217e-03 -5.2816868e-05  2.6935578e-04\n",
      " -1.6880632e-04 -4.7855065e-03  4.3134023e-03 -2.1719194e-03\n",
      "  2.1035396e-03  6.6652300e-04  5.9696771e-03 -6.8423809e-03\n",
      " -6.8157101e-03 -4.4762576e-03  9.4358288e-03 -1.5918827e-03\n",
      " -9.4292425e-03 -5.4504158e-04 -4.4489228e-03  6.0000787e-03\n",
      " -9.5836855e-03  2.8590010e-03 -9.2528323e-03  1.2498009e-03\n",
      "  5.9991982e-03  7.3973476e-03 -7.6214634e-03 -6.0530235e-03\n",
      " -6.8384409e-03 -7.9183402e-03 -9.4990805e-03 -2.1254970e-03\n",
      " -8.3593250e-04 -7.2562015e-03  6.7870365e-03  1.1196196e-03\n",
      "  5.8288667e-03  1.4728665e-03  7.8936579e-04 -7.3681297e-03\n",
      " -2.1766580e-03  4.3210792e-03 -5.0853146e-03  1.1307895e-03\n",
      "  2.8833640e-03 -1.5363609e-03  9.9322954e-03  8.3496347e-03\n",
      "  2.4156666e-03  7.1182456e-03  5.8914376e-03 -5.5806171e-03]\n"
     ]
    }
   ],
   "source": [
    "# Access word embeddings\n",
    "word_vector = model.wv['programming']\n",
    "print(\"Embedding for 'programming':\", word_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importance of Word Embeddings:\n",
    "1. **Semantic Relationships**: Word embeddings capture semantic relationships between words. This is crucial for translation, where understanding the meaning and context of words in both languages is necessary for accurate translation.\n",
    "2. **Voice Cloning:** Voice cloning involves generating speech in a person's voice. Word embeddings can help capture the unique speaking style and intonation of the person, contributing to a more natural and coherent cloned voice.\n",
    "3. **Emotion Transfer:** Emotion transfer involves modifying the emotional tone of speech. Word embeddings can help identify words associated with specific emotions and aid in modifying the speech to convey the desired emotion.\n",
    "4. **Translation Context:** Word embeddings provide context to translated words. This helps in translating idiomatic expressions, cultural nuances, and preserving the intended meaning during translation.\n",
    "5. **Handling Rare Words:** In translation and voice cloning, encountering rare or out-of-vocabulary words is common. Word embeddings can map these words to similar words in the vector space, enabling the model to handle such words effectively.\n",
    "6. **Dimensionality Reduction:** Word embeddings reduce the high-dimensional space of words into a lower-dimensional continuous space. This enhances efficiency and simplifies calculations in various tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
